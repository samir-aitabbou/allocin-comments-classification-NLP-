{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7638e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Initialisation du générateur de nombres aléatoires\n",
    "random.seed(123)\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r'''\\w'|\\w+|[^\\w\\s]''')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Reshape, SpatialDropout1D\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bfb623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Télécharge les données nécessaires pour le tokenizer (segmenteur) de phrases et de mots\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Télécharge la liste de mots vides (stopwords) pour différentes langues\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('cleaned_data/train_cleaned.csv',index_col=0)\n",
    "dev_data   = pd.read_csv('cleaned_data/dev_cleaned.csv',index_col=0)\n",
    "test_data  =  pd.read_csv('cleaned_data/test_cleaned.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# train_data = train_data.head(200)\n",
    "# dev_data = dev_data.head(50)\n",
    "# test_data = test_data.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42951849",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['commentaire'] = train_data['commentaire'].astype(str)\n",
    "dev_data['commentaire'] = dev_data['commentaire'].astype(str)\n",
    "test_data['commentaire'] = test_data['commentaire'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d60adf",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2cbae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data['commentaire']\n",
    "X_dev = dev_data['commentaire']\n",
    "X_test = test_data['commentaire']\n",
    "\n",
    "y_train = train_data['note']\n",
    "y_dev = dev_data['note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85af6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b339cec",
   "metadata": {},
   "source": [
    "# Y one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hotencoding = to_categorical(y_train, num_classes=10)\n",
    "print(y_train_one_hotencoding[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e72add",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_one_hotencoding = to_categorical(y_dev, num_classes=10)\n",
    "print(y_dev_one_hotencoding[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(X_train.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6a5f3",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_most_common_words = 10000\n",
    "max_len = 180\n",
    "\n",
    "tokenizer = Tokenizer(num_words=n_most_common_words)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train) \n",
    "X_dev = tokenizer.texts_to_sequences(X_dev)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_dev = pad_sequences(X_dev, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb494a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626926d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "emb_dim = 128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((X_train.shape, y_train_one_hotencoding.shape, X_dev.shape, y_dev_one_hotencoding.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5298947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_most_common_words, emb_dim, input_length=X_train.shape[1]))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(LSTM(256, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Create callbacks\n",
    "filepath = 'Lstm_best_model.hdf5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,  # Increased patience\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early_stopping]\n",
    "\n",
    "# Training\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train_one_hotencoding, epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_dev, y_dev_one_hotencoding), verbose=1, callbacks=callbacks)\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print('Execution time:', time.strftime(\"%H:%M:%S\", time.gmtime(execution_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df24342b",
   "metadata": {},
   "source": [
    "# save train and validation accuracy/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dced1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_plot.png')  # Save the plot as an image\n",
    "\n",
    "# Clear the figure for the next plot\n",
    "plt.figure()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('loss_plot.png')  # Save the plot as an image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b74ef",
   "metadata": {},
   "source": [
    "# Test and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201e46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# model = load_model('MLP_Best_One.hdf5'),this command doesn't work for me, i had to change the saved model path\n",
    "\n",
    "modelpath = \"C:/trained_Models/Lstm_best_model.hdf5\"\n",
    "\n",
    "# Load the model with compile=False\n",
    "Lstm_best_model = load_model(modelpath)\n",
    "\n",
    "X_test = test_data['commentaire']\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "predictions = Lstm_best_model.predict(X_test)\n",
    "argmax_predictions = np.argmax(predictions,axis =1)\n",
    "\n",
    "print(\"argmax_predictions: \",argmax_predictions)\n",
    " \n",
    "# # generate the plateform test data format        \n",
    "with open(\"LSTM_ID_Prediction_improved.txt\", \"w\") as f:\n",
    "    for i in range(len(test_data['review_id'])):\n",
    "        prediction = (argmax_predictions[i] + 1) / 2\n",
    "        line = f\"{test_data['review_id'].iloc[i]} {str(prediction).replace('.', ',')}\\n\"\n",
    "        f.write(line)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d201a3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
